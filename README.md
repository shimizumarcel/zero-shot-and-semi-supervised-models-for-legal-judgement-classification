# zero-shot-and-semi-supervised-models-for-legal-judgement-classification

Repository for the MBA Thesis in Data Science (CeMEAI-USP)

## Project Summary
This project explores Natural Language Processing (NLP) techniques for automatically classifying Brazilian legal judgments ("acórdãos") into "favorable" or "unfavorable" to the appellant. Implemented approaches include:

- **Baseline**: Supervised Naive Bayes
- **Zero-Shot Approaches**:
  - Text Entailment (XLM-RoBERTa-large-XNLI)
  - Similarity-based (LegalBERTimbau vs BERTimbau)
- **Semi-Supervised Learning**: Domain Adaptation on BERTimbau

Key result: The zero-shot text entailment model achieved **80.77% accuracy**, outperforming the baseline (75.64%).

## Repository Structure
├── data/
│ ├── download_data.py # Dataset download script
│ └── processed/ # Processed data (generated by the script)
├── notebooks/ # Original Jupyter notebooks converted to scripts
│ ├── data_preprocessing.py
│ ├── domain_adaptation.py
│ ├── naive_bayes.py
│ ├── similarity_based.py
│ └── text_entailment.py
└── README.md # This documentation file

## Requirements & Installation
1. Clone repository:
2. Install dependencies
3. Download data

## How to Run

Each approach can be executed independently:

# Naive Bayes (baseline)
python notebooks/naive_bayes.py

# Zero-shot Text Entailment
python notebooks/text_entailment.py

# Similarity-based
python notebooks/similarity_based.py

# Domain Adaptation
python notebooks/domain_adaptation.py

Key Results
| Approach                      | Accuracy | F1-Score (Favorable) | F1-Score (Unfavorable) |
|-------------------------------|:--------:|:--------------------:|:----------------------:|
| Naive Bayes (baseline)        | 75.64%   | 0.68                 | 0.80                   |
| Zero-shot Text Entailment     | 80.77%   | 0.77                 | 0.84                   |
| Similarity-based (LegalBERT)  | 66.67%   | 0.59                 | 0.72                   |
| Domain Adaptation             | 65.38%   | 0.65                 | 0.66                   |

References:
- AKIBA, Takuya et al. Optuna: a next-generation hyperparameter optimization framework. 2019. Disponível em: https://arxiv.org/abs/1907.10902. Acesso em: 27 jan. 2025.
- BA, Jimmy Lei; KIROS, Jamie Ryan; HINTON, Geoffrey E. Layer Normalization. 2016. Disponível em: https://arxiv.org/abs/1607.06450. Acesso em: 6 fev. 2025.
- BOSTAN, Laura Ana Maria; KLINGER, Roman. An analysis of annotated corpora for emotion classification in text. In: INTERNATIONAL CONFERENCE ON COMPUTATIONAL LINGUISTICS – COLING, 27., 2018, Santa Fé. Proceedings […]. Stroudsburg: Association for Computational Linguistics, 2018. p. 2104–2119. Disponível em: https://aclanthology.org/C18-1179/. Acesso em: 05 fev. 2025.
- CASELI, H. M.; NUNES, M. G. V. (org.). Processamento de Linguagem Natural: conceitos, técnicas e aplicações em português. 2. ed. BPLN, 2024. Disponível em: https://brasileiraspln.com/livro-pln/2a-edicao. Acesso em: 05 fev. 2025.
- CHANG, M.; VIVEK, et al. Importance of semantic representation: dataless classification. In: AAAI CONFERENCE ON ARTIFICIAL INTELLIGENCE – AAAI, 23., 2008, Menlo Park. Proceedings [...]. Menlo Park: AAAI Press, 2008. p. 830–835. Disponível em: https://cdn.aaai.org/AAAI/2008/AAAI08-132.pdf. Acesso em: 05 fev. 2025.
- CHAPELLE, Olivier; SCHÖLKOPF, Bernhard; ZIEN, Alexander (org.). Semi-supervised learning. Cambridge: MIT Press, 2006.
- CONNEAU, A. et al. Unsupervised cross-lingual representation learning at scale. In: CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING –EMNLP-IJCNLP, 2019, Hong Kong, China. Proceedings [...]. [S.l.]: [s.n.], 2019. Disponível em: https://arxiv.org/abs/1911.02116. Acesso em: 25 dez 2024.
- DEVLIN, J. et al. BERT: pre-training of deep bidirectional transformers for language understanding. In: CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES – NAACL-HLT, 2019. Proceedings [...]. [S.l.]: [s.n.], 2019. p. 4171-4186. Disponível em: https://arxiv.org/pdf/1810.04805. Acesso em: 07 set 2024.
- HKPROJ. Transformer from scratch notes – diagrams V2. Disponível em: https://github.com/hkproj/transformer-from-scratch-notes/blob/main/Diagrams_V2.pdf. Acesso em: 30 nov 2024.
- HUMBY, Clive. Data is the new oil! Palestra apresentada no ANA SENIOR MARKETER’S SUMMIT, Kellogg School, 2006.
- MAYHEW, Stephen et al. University of Pennsylvania LORELEI-HLT 2019 submission. In: LORELEI-HLT WORKSHOP, 2019. Proceedings [...]. [S.l.]: [s.n.], 2019.
- NOGUTI, Mariana Yukari; VELLASQUES, Edduardo; OLIVEIRA, Luiz Eduardo Soares. A small claims court for the NLP: judging legal text classification strategies with small datasets. 2024. Disponível em: https://arxiv.org/abs/2409.05972. Acesso em: 7 set 2024.
- RAINA, Rajat; NG, Andrew Y.; KOLLER, Daphne. Constructing informative priors using transfer learning. In: INTERNATIONAL CONFERENCE ON MACHINE LEARNING – ICML, 23., 2006, Pittsburgh. Proceedings [...]. New York: ACM, 2006. p. 713–720. Disponível em: https://dl.acm.org/doi/10.1145/1143844.1143934. Acesso em: 28 jan. 2025.
- RIETZLER, Alexander et al. Adapt or get left behind: domain adaptation through BERT language model finetuning for aspect-target sentiment classification. In: INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION – LREC, 12., 2020, Marseille. Proceedings [...]. Stroudsburg: European Language Resources Association, 2020. p. 4933–4941. Disponível em: https://aclanthology.org/2020.lrec-1.607/. Acesso em: 28 jan. 2025.
- SCHOPF, T.; BRAUN, Daniel; MATTHES, Florian. Evaluating unsupervised text classification: zero-shot and similarity-based approaches. In: INTERNATIONAL CONFERENCE ON NATURAL LANGUAGE PROCESSING, 2023, Bangkok, Thailand.Proceedings [...]. [S.l.]: [s.n.], 2023. Disponível em: https://arxiv.org/abs/2211.16285. Acesso em: 07 set 2024.
- SOUSA, A. William; DEL FABRO, Marcos Didonet. Iudicium Textum Dataset: annotated legal dataset for natural language processing tasks in Portuguese. Disponível em: https://www.inf.ufpr.br/didonet/articles/2019_dsw_Iudicium_Textum_Dataset.pdf. Acesso em: 13 maio 2024.
- TUNSTALL, L.; WERRA, Leandro V.; WOLF, Thomas. Natural language processing with transformers. Sebastopol: O'Reilly Media, 2022.
- VASWANI, A. et al. Attention is all you need. In: ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS – NEURIPS, 2017. Proceedings [...]. [S.l.]: [s.n.], 2017. p. 5998-6008. Disponível em: https://arxiv.org/pdf/1706.03762. Acesso em: 07 set 2024.
- YIN, Wenpeng; HAY, Jamaal; ROTH, Dan. Benchmarking zero-shot text classification: datasets, evaluation and entailment approach. In: CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING – EMNLP-IJCNLP, 2019, Hong Kong. Proceedings [...]. Stroudsburg: Association for Computational Linguistics, 2019. p. 3914–3923. Disponível em: https://aclanthology.org/D19-1404.pdf. Acesso em: 27 jan. 2025.
- WIKIPEDIA CONTRIBUTORS. Naive Bayes classifier. Wikipedia, The Free Encyclopedia, 2024. Disponível em: https://en.wikipedia.org/wiki/Naive_Bayes_classifier. Acesso em: 30 out. 2024.
- WORDNET. A lexical database for English. Princeton University, 2024. Disponível em: https://wordnet.princeton.edu/. Acesso em 05 fev. 2025.
- ZHANG, Xiang; ZHAO, Junbo Jake; LECUN, Yann. Character-level convolutional networks for text classification. In: ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS – NIPS, 28., 2015, Montreal. Proceedings [...]. Montreal: Curran Associates,2015. p. 649–657. Disponível em: https://papers.nips.cc/paper_files/paper/2015/hash/250cf8b51c773f3f8dc8b4be867a9a02-Abstract.html. Acesso em: 27 jan. 2025.
